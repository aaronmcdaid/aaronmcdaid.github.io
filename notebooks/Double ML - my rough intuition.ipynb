{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML is great at prediction, but usually not so good at causal inference. But this paper is changing my mind! Iâ€™ll try to share a little intuition in a few tweets.\n",
    "\n",
    "\"Double/Debiased Machine Learning for Treatment and Causal Parameters\"\n",
    "\n",
    "https://arxiv.org/abs/1608.00060"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some definitions:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "X: & \\; \\mbox{pre-experiment covariates} \\\\\n",
    "D \\in \\{0,1\\}: & \\; \\mbox{treatment indicator. Depends on $X$ (in an unknown way)} \\\\ \n",
    "Y: & \\; \\mbox{outcome. Depends on $X$ and $D$} \\\\\n",
    "\\theta_0: & \\; \\mbox{the effect of $D$ on $Y$, this is what we want to estimate} \\\\\n",
    "\\mbox{More formally}: & \\\\\n",
    "& Y = D \\theta_0 + g(X) + U, \\qquad \\mathbb{E}(U|X, D) = 0 \\\\\n",
    "& D = m(X) + V, \\; \\qquad \\qquad \\mathbb{E}(V|X) = 0 \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a long paper, but the first 7 pages really cover all the basics well. I'm new to this, so forgive any mistakes I make. And I can't do it justice here; so I'll focus only on the ideas that I recognized from other research and start with something very basic:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do a survey of incomes, we know that many will fail to respond. Let's assume we know, as a function of the age ($X$), the probability of responding, ğ‘š(ğ‘‹). We can then get an unbiased estimate with a weighted average, weighting by the inverse probability\n",
    "\n",
    "$$\n",
    "\\left( \\sum_{i \\in I} \\frac{1}{m(X)} \\right)^{-1}  \\sum_{i \\in I} \\frac{Y_i}{m(X)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll leave out the normalizing constant:\n",
    "\n",
    "$$\n",
    "\\propto  \\sum_{i \\in I} \\frac{Y_i}{m(X)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, in an AB test where the probability of being assigned to the treatment group, ğ‘ƒ(ğ·=1|ğ‘‹) = ğ‘š(ğ‘‹) , as opposed to the control group, ğ·=0, is a function of pre-experiment covariates $X$, we can estimate the difference as:\n",
    "\n",
    "$$\n",
    "\\propto \\sum_{i \\in I} \\frac{D_iY_i}{m(X)}-\\frac{(1-D_i)Y_i}{1-m(X)}\n",
    "\\\\\n",
    "\\propto \\sum_{i \\in I} \\left( \\frac{D_i}{m(X)}-\\frac{(1-D_i)}{1-m(X)} \\right) Y_i\n",
    "\\\\\n",
    "\\mbox{multiply by $m(X)(1-m(X))$ and move it}\n",
    "\\\\\n",
    "\\mbox{into the normalizing constant as it doesn't involve $Y$:}\n",
    "\\\\\n",
    "\\propto  \\sum_{i \\in I} \\big(D_i (1{-}m(X))\\big) - \\big((1-D_i) m(X)\\big) Y_i\n",
    "\\\\\n",
    "= \\left(\\sum_{i \\in I} \\big( D_i - m(X) \\big) D_i \\right)^{-1} \\sum_{i \\in I} \\big( D_i - m(X) \\big) Y_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't know the true ğ‘š(ğ‘‹) function, but the paper shows that we can plug in an estimate from any ML method even though those methods are known to be biased.\n",
    "\n",
    "Also, to borrow an idea from Variance Reduction, imagine we have a prediction model for Y as a function of X, then we can simply subtract this prediction from our Ys:\n",
    "\n",
    "$$\n",
    "E[Y|X] \\approx g(X)\n",
    "\\\\\n",
    "= \\left(\\sum_{i \\in I} \\big( D_i - m(X) \\big) D_i \\right)^{-1} \\sum_{i \\in I} \\big( D_i - m(X) \\big) (Y_i - \\hat{g}(X_i))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With good - but potentially biased - estimates of the ğ‘š(ğ‘‹) and ğ‘”(ğ‘‹) functions, the paper shows how the estimate of Î¸ is unbiased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
